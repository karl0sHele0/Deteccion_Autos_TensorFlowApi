{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detección de Autos con Object Detection Api [TensorFlow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import tensorflow as tf\n",
    "import PIL.Image as Image\n",
    "import PIL.ImageDraw as ImageDraw\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.display import HTML\n",
    "from collections import defaultdict\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comandos para crear las librerias de object detection\n",
    "# Ejecutarlas mediante shell\n",
    "#$ cd models/research\n",
    "#$ ./bin/protoc object_detection/protos/*.proto --python_out=.\n",
    "#$ export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim\n",
    "\n",
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ubicar dirección del video</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_VIDEO = Path(\"../Videos/Prueba1.mp4\")\n",
    "if not PATH_VIDEO.exists():\n",
    "    print(\"El video {} no existe\".format(PATH_VIDEO))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Establecer los datos del modelo</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#direccion del modelo\n",
    "PATH_MODEL = Path('../ssd_mobilenet_v1_coco_2017_11_17/saved_model/')\n",
    "if not PATH_MODEL.is_dir():\n",
    "    print(\"La carpeta del modelo {} no existe\".format(PATH_MODEL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Función para cargar el modelo</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_modelo(path_modelo):\n",
    "    model = tf.saved_model.load(str(path_modelo))\n",
    "    model = model.signatures['serving_default']  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Función para Inferir un Frame/Imagen</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferir_imagen(modelo, img_Inicial):\n",
    "    \n",
    "    #Convertir la imagen en arreglo\n",
    "    img_array = np.asarray(img_Inicial)\n",
    "    \n",
    "    # La entrada debe ser un tensor, convertirlo usando 'tf.convert_to_tensor'\n",
    "    input_tensor = tf.convert_to_tensor(img_array)\n",
    "    \n",
    "    # El modelo espera las imagenes, asi que se agrega un eje con 'tf.newaxis'\n",
    "    input_tensor = input_tensor[tf.newaxis,...]\n",
    "    \n",
    "    # Ejecutar la inferencia\n",
    "    output_dict = modelo(input_tensor)\n",
    "    \n",
    "    num_detections = int(output_dict.pop('num_detections'))\n",
    "    #Reducimos el numero de detecciones a num_detections = 7\n",
    "    num_detections = 7\n",
    "    \n",
    "    output_dict = {key:value[0, :num_detections].numpy() \n",
    "                 for key,value in output_dict.items()}\n",
    "    \n",
    "    # detection_classes deben ser ints.\n",
    "    output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
    "   \n",
    "    toReplace = np.where((output_dict['detection_classes'] != 3 ))\n",
    "    #Reemplazamos los scores/puntajes de cualquier otro objeto para ignorarlo\n",
    "    output_dict['detection_scores'].flat[toReplace] = 0.00111111\n",
    "    \n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "    <b>Función para convertir las coordenadas del modelo</b><br>\n",
    "    Las funcion convertira las coordenadas obtenidas en\n",
    "    output_dict['detection_boxes'] de la inferencia del frame, \n",
    "    para retornarlas en formato de pixeles  a escala de la imagen\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_Coordenadas(arr_coor,img_ancho,img_alto):\n",
    "    #[(248,84),(248,139),(396,139),(396,84),(248,84)]\n",
    "    (left, right, top, bottom) = (arr_coor[1] * img_ancho, arr_coor[3] * img_ancho,\n",
    "                                  arr_coor[0] * img_alto, arr_coor[2] * img_alto)\n",
    "\n",
    "    return [(left, top), (left, bottom), (right, bottom), (right, top), (left, top)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFrame(modelo, frame_base):\n",
    "    img_inicial = np.array(frame_base)\n",
    "    result_inferencia = inferir_imagen(modelo, img_inicial)\n",
    "    alto, ancho = frame_base.shape[0], frame_base.shape[1]\n",
    "    \n",
    "    #Si es un auto\n",
    "    if (result_inferencia['detection_classes'][0] == 3) & (result_inferencia['detection_scores'][0] > float(0.45000000)):\n",
    "        #print(result_inferencia['detection_scores'][0])\n",
    "        \n",
    "        coordenadas = calcular_Coordenadas(result_inferencia['detection_boxes'][0],ancho,alto)\n",
    "    \n",
    "        img_Pil = Image.fromarray(img_inicial)\n",
    "        marco = ImageDraw.Draw(img_Pil)\n",
    "        marco.line(coordenadas, fill=\"green\",width=3) \n",
    "        #Regresa el freme con la deteccion del auto\n",
    "        return np.asarray(img_Pil)\n",
    "    \n",
    "    #Regresa el frame igual\n",
    "    return frame_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# Cargar el modelo de detección\n",
    "MODEL_DETECTION = cargar_modelo(PATH_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(str(PATH_VIDEO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargar codec seleccionado (*mp4 es por defecto util en opencv para procesar videos en formatos MP4 )\n",
    "fourcc = cv.VideoWriter_fourcc(*'mp4v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establecer la configuracion del escritor del Video de OpenCV (VideoWriter)\n",
    "# formato (VIDEO DESTINO, CODEC, FPS, Dimensiones de los frames)\n",
    "out = cv.VideoWriter('../Videos/Video_p4.mp4',fourcc, 29.04, (640,352))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin del procesamiento\n"
     ]
    }
   ],
   "source": [
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "        #grayFrame0 = cv.cvtColor(frame, cv.COLOR_BGR2GRAY,0)\n",
    "        #grayFrame = cv.cvtColor(grayFrame0,cv.COLOR_GRAY2BGR,0)\n",
    "        \n",
    "        #Convertimos el frame a escala de colores\n",
    "        grayFrame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "        grayFrame = cv.cvtColor(grayFrame,cv.COLOR_GRAY2RGB)\n",
    "        #Obtenemos el Frame final con la deteccion\n",
    "        finalFrame = getFrame(MODEL_DETECTION, grayFrame)\n",
    "        #Antes de escribirl se necesita en BGR\n",
    "        finalFrame = cv.cvtColor(finalFrame, cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        #Escribir el frame en el video\n",
    "        out.write(finalFrame)\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "# Liberar la memoria utilizada\n",
    "# del procesamiento del video(cap)\n",
    "# y su escritura (out)\n",
    "cap.release()\n",
    "out.release()\n",
    "print(\"Video Guardado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comando para verificar los codecs de video [FFMPEG]\n",
    "#!ffmpeg -encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversión Completa\n"
     ]
    }
   ],
   "source": [
    "#Comando para converion de video [El proceso puede tardar unos segundos]\n",
    "!ffmpeg -i ../Videos/Video_p4.mp4 -c:v libx264 ../Videos/Video_pf.mp4 -y 2> /dev/null\n",
    "print(\"Conversión Completa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style> video {  max-width: 100%;  height: auto; } </style>\n",
       "    <video alt=\"test\" controls autoplay>\n",
       "        <source src=\"../Videos/Video_pf.mp4\" type=\"video/webm\">\n",
       "    </video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cargar el video codificado en la Notebook\n",
    "HTML(\"\"\"\n",
    "<style> video {  max-width: 100%;  height: auto; } </style>\n",
    "    <video alt=\"test\" controls autoplay>\n",
    "        <source src=\"../Videos/Video_pf.mp4\" type=\"video/webm\">\n",
    "    </video>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
