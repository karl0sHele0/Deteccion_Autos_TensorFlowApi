{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import tensorflow as tf\n",
    "import PIL.Image as Image\n",
    "import PIL.ImageDraw as ImageDraw\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.display import HTML\n",
    "from IPython.display import display\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'object_detection'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-136de77a12d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#$ export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualization_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvis_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'object_detection'"
     ]
    }
   ],
   "source": [
    "# Comandos para crear las librerias ~ object detection\n",
    "# Ejecutarlas mediante shell\n",
    "#$ cd models/research\n",
    "#$ ./bin/protoc object_detection/protos/*.proto --python_out=.\n",
    "#$ export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim\n",
    "\n",
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ubicar dirección del video</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_VIDEO = Path(\"../Videos/Prueba1.mp4\")  #Prueba1\n",
    "if not PATH_VIDEO.exists():\n",
    "    print(\"El video {} no existe\".format(PATH_VIDEO))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Establecer los datos del modelo</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dirección del modelo\n",
    "PATH_MODEL = Path('../ssd_mobilenet_v1_coco_2017_11_17/saved_model/')\n",
    "if not PATH_MODEL.is_dir():\n",
    "    print(\"La carpeta del modelo {} no existe\".format(PATH_MODEL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Función para cargar el modelo</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_modelo(path_modelo):\n",
    "    model = tf.saved_model.load(str(path_modelo))\n",
    "    model = model.signatures['serving_default']  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "MODEL_DETECTION = cargar_modelo(PATH_MODEL) # Cargar el modelo de detección"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Función para Inferir un Frame/Imagen</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "    <b>Función para convertir las coordenadas del modelo</b><br>\n",
    "    Las funcion convertira las coordenadas obtenidas en\n",
    "    output_dict['detection_boxes'] de la inferencia del frame, \n",
    "    para retornarlas en formato de pixeles  a escala de la imagen\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferir_imagen(modelo, img_Inicial):\n",
    "    \n",
    "    img_array = np.asarray(img_Inicial) # Convertir la imagen en arreglo\n",
    "    \n",
    "    # La entrada debe ser un tensor, convertirlo usando 'tf.convert_to_tensor'\n",
    "    input_tensor = tf.convert_to_tensor(img_array)\n",
    "    \n",
    "    # El modelo espera las imagenes, asi que se agrega un eje con 'tf.newaxis'\n",
    "    input_tensor = input_tensor[tf.newaxis,...]\n",
    "    \n",
    "    # Enviar el tensor de la imagen al modelo ~ ejecutar la inferencia\n",
    "    output_dict = modelo(input_tensor)\n",
    "    \n",
    "    num_detections = int(output_dict.pop('num_detections'))\n",
    "    num_detections = 10  #Reducir el total de detecciones \n",
    "    \n",
    "    clases_detectadas = []\n",
    "    coord_finales = []\n",
    "    \n",
    "    for key in output_dict['detection_classes']:\n",
    "        clases_detectadas = key[0:num_detections].numpy()\n",
    "        # Seleccionar las clases que pertenecen a un carro(3) o una camioneta(8)\n",
    "        clases_detectadas = np.where( (clases_detectadas == 3) | (clases_detectadas == 8) )\n",
    "        \n",
    "    #Almacena los scores obtenidos en un numpy array\n",
    "    detected_scores = output_dict['detection_scores'][0].numpy()\n",
    "    detected_boxes = output_dict['detection_boxes'][0].numpy()\n",
    "    \n",
    "    for key in clases_detectadas[0]:\n",
    "        if detected_scores[key] > float(0.08):       \n",
    "            coord_finales.append(detected_boxes[key]) # Almacenar las coordenadas con un score mayor a 45%\n",
    "        \n",
    "    return coord_finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversion_Coordenadas(arr_coor,img_ancho,img_alto):\n",
    "    #[(248,84),(248,139),(396,139),(396,84),(248,84)]\n",
    "    (left, right, top, bottom) = (arr_coor[1] * img_ancho, arr_coor[3] * img_ancho,\n",
    "                                  arr_coor[0] * img_alto, arr_coor[2] * img_alto)\n",
    "\n",
    "    return [(left, top), (left, bottom), (right, bottom), (right, top), (left, top)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(str(PATH_VIDEO))            # Captura del video por OpenCV\n",
    "Numframe = 0                                      # Numero de frame actual\n",
    "FRAME_STOP = 1000                                 # Frame Limite a procesar\n",
    "Total_fr = cap.get(cv.CAP_PROP_FRAME_COUNT)       # Total de frames del video\n",
    "ANCHO_V  = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))  # float ~ Ancho del video\n",
    "ALTO_V = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))   # float ~ Alto del video\n",
    "FPS_V = int(cap.get(cv.CAP_PROP_FPS))             # Frame por segundos (Frame per second)\n",
    "TEXT_FONT = cv.FONT_HERSHEY_PLAIN                 # Estilo de texto de openCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar codec seleccionado (*mp4 es por defecto útil en opencv para procesar videos en formatos MP4 )\n",
    "fourcc = cv.VideoWriter_fourcc(*'mp4v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecer la configuracion del escritor del Video de OpenCV (VideoWriter)\n",
    "# Formato de VideoWriter(VIDEO DESTINO, CODEC, FPS, Dimensiones de los frames(Ancho,Alto))\n",
    "out = cv.VideoWriter('../Videos/Video_p4.mp4',fourcc, FPS_V, (ANCHO_V,ALTO_V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escala de centimetros cuadrados de un pixel\n",
    "DIM_PIXEL = 3.04  #3.3\n",
    "CAR_DETECTIONS = 0\n",
    "CAR_DETECTED = False\n",
    "COORD_INICO = []\n",
    "FRAME_INICIO = 0\n",
    "VELOCIDAD_CARRO = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcVelocidad(coorInicial,coorFinal,nFrameI,nFrameF,FPS,dimPixel):\n",
    "    print(\"Calculando Velocidad\")\n",
    "    #Calcular la distancia recorrida en pixeles\n",
    "    dist = math.sqrt((int(coorFinal[0][0]) - int(coorInicial[3][0]))**2 + (int(coorFinal[0][1]) - int(coorInicial[3][1]))**2)  \n",
    "    \n",
    "    frames_dist = nFrameF - nFrameI\n",
    "    tiempo_trans = (1/FPS) * frames_dist\n",
    "    \n",
    "    #distancia en metros\n",
    "    dist = (dist*dimPixel)/100\n",
    "    #Velocidad en KM/H\n",
    "    velocidad = (dist / tiempo_trans) * 3.6\n",
    "    #print(\"Distancia en metros: {} recorridos\".format(dist))\n",
    "    #print(\"Velocidad: {} km/h\".format(velocidad))\n",
    "    return int(velocidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infiriendo Frame: 80 de 80.0\n",
      "Inferencia completa ~ video Guardado!\n"
     ]
    }
   ],
   "source": [
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        Numframe += 1\n",
    "        if Numframe <= FRAME_STOP:\n",
    "            grayFrame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "            grayFrame = cv.cvtColor(grayFrame,cv.COLOR_GRAY2RGB)\n",
    "\n",
    "            clear_output(wait=True)    \n",
    "            print(\"Infiriendo Frame: {} de {}\".format(Numframe,Total_fr))\n",
    "            \n",
    "            #Inferir la imagen y obtener coordenadas de la detección\n",
    "            coordenadas_detectadas = inferir_imagen(MODEL_DETECTION,grayFrame)\n",
    "            \n",
    "            #Dibujar las detecciones en el frame si fuerón encontrados autos\n",
    "            if (len(coordenadas_detectadas)> 0) & (Numframe < (Total_fr-3)) :              \n",
    "                nCoord = []\n",
    "                for coordenada in coordenadas_detectadas:\n",
    "                    nCoord = conversion_Coordenadas(coordenada,ANCHO_V,ALTO_V)\n",
    "                    grayFrame = cv.rectangle(grayFrame, \n",
    "                                (int(nCoord[0][0]),int(nCoord[0][1])), (int(nCoord[2][0]),int(nCoord[2][1])), (0,0,255), 2) \n",
    "                \n",
    "                #print(\"Carros Detectados\")\n",
    "                if ((CAR_DETECTIONS < 3) & (CAR_DETECTED==False)):\n",
    "                    CAR_DETECTIONS += 1\n",
    "                elif ((CAR_DETECTIONS == 3) & (CAR_DETECTED == False)):\n",
    "                    CAR_DETECTED = True\n",
    "                    COORD_INICO = nCoord\n",
    "                    #print(\"Carro Detectado\")\n",
    "                    CAR_DETECTIONS += 1\n",
    "                    FRAME_INICIO = Numframe\n",
    "                    \n",
    "            elif CAR_DETECTED:\n",
    "                CAR_DETECTIONS -= 1\n",
    "                if CAR_DETECTIONS == 0:\n",
    "                    CAR_DETECTED = False\n",
    "                    VELOCIDAD_CARRO = calcVelocidad(COORD_INICO,nCoord,FRAME_INICIO,Numframe,FPS_V,DIM_PIXEL)\n",
    "                \n",
    "                \n",
    "            grayFrame = cv.putText(grayFrame, 'Frame : {} Velocidad {} KM/H'.format(Numframe,VELOCIDAD_CARRO), (10,30), TEXT_FONT,2, (0,255,0), 2) \n",
    "            finalFrame = cv.cvtColor(np.asarray(grayFrame), cv.COLOR_RGB2BGR)  #Converion de RGB a BGR\n",
    "                 \n",
    "            #Mostrar frame como imagen\n",
    "            #display(Image.fromarray(finalFrame))   \n",
    "            #Escribir el frame en el video\n",
    "            out.write(finalFrame)              \n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Liberar la memoria utilizada\n",
    "# del procesamiento del video(cap)\n",
    "# y su escritura (out)\n",
    "cap.release()\n",
    "out.release()\n",
    "print(\"Inferencia completa ~ video Guardado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversión Completa\n"
     ]
    }
   ],
   "source": [
    "# Comando para conversion de video [El proceso puede tardar unos segundos]\n",
    "!ffmpeg -i ../Videos/Video_p4.mp4 -c:v libx264 ../Videos/Video_pf.mp4 -y 2> /dev/null\n",
    "print(\"Conversión Completa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style> video {  max-width: 100%;  height: auto; } </style>\n",
       "    <video alt=\"test\" controls autoplay>\n",
       "    <source src=\"../Videos/Video_pf.mp4\" type=\"video/webm\"> \n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el video codificado en la Notebook\n",
    "HTML(\"\"\"\n",
    "<style> video {  max-width: 100%;  height: auto; } </style>\n",
    "    <video alt=\"test\" controls autoplay>\n",
    "    <source src=\"../Videos/Video_pf.mp4\" type=\"video/webm\"> \n",
    "    </video>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
