{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_VIDEO = Path(\"../Videos/Prueba2.mp4\")  #Prueba1\n",
    "if not PATH_VIDEO.exists():\n",
    "    print(\"El video {} no existe\".format(PATH_VIDEO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dirección del modelo\n",
    "PATH_MODEL = Path('../ssd_mobilenet_v1_coco_2017_11_17/saved_model/')\n",
    "if not PATH_MODEL.is_dir():\n",
    "    print(\"La carpeta del modelo {} no existe\".format(PATH_MODEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_modelo(path_modelo):\n",
    "    model = tf.saved_model.load(str(path_modelo))\n",
    "    model = model.signatures['serving_default']  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "MODEL_DETECTION = cargar_modelo(PATH_MODEL) # Cargar el modelo de detección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferir_imagen(modelo, img_Inicial):\n",
    "    \n",
    "    img_array = np.asarray(img_Inicial) # Convertir la imagen en arreglo\n",
    "    \n",
    "    # La entrada debe ser un tensor, convertirlo usando 'tf.convert_to_tensor'\n",
    "    input_tensor = tf.convert_to_tensor(img_array)\n",
    "    \n",
    "    # El modelo espera las imagenes, asi que se agrega un eje con 'tf.newaxis'\n",
    "    input_tensor = input_tensor[tf.newaxis,...]\n",
    "    \n",
    "    # Enviar el tensor de la imagen al modelo ~ ejecutar la inferencia\n",
    "    output_dict = modelo(input_tensor)\n",
    "    \n",
    "    num_detections = int(output_dict.pop('num_detections'))\n",
    "    num_detections = 10  #Reducir el total de detecciones \n",
    "    \n",
    "    clases_detectadas = []\n",
    "    coord_finales = []\n",
    "    \n",
    "    for key in output_dict['detection_classes']:\n",
    "        clases_detectadas = key[0:num_detections].numpy()\n",
    "        # Seleccionar las clases que pertenecen a un carro(3) o una camioneta(8)\n",
    "        clases_detectadas = np.where( (clases_detectadas == 3) | (clases_detectadas == 8) )\n",
    "        \n",
    "    #Almacena los scores obtenidos en un numpy array\n",
    "    detected_scores = output_dict['detection_scores'][0].numpy()\n",
    "    detected_boxes = output_dict['detection_boxes'][0].numpy()\n",
    "    \n",
    "    for key in clases_detectadas[0]:\n",
    "        if detected_scores[key] > float(0.5):       \n",
    "            coord_finales.append(detected_boxes[key]) # Almacenar las coordenadas con un score mayor a 45%\n",
    "        \n",
    "    return coord_finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversion_Coordenadas(arr_coor,img_ancho,img_alto):\n",
    "    #[(248,84),(248,139),(396,139),(396,84),(248,84)]\n",
    "    (left, right, top, bottom) = (arr_coor[1] * img_ancho, arr_coor[3] * img_ancho,\n",
    "                                  arr_coor[0] * img_alto, arr_coor[2] * img_alto)\n",
    "\n",
    "    return [(left, top), (left, bottom), (right, bottom), (right, top), (left, top)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcVelocidad(coorInicial,coorFinal,nFrameI,nFrameF,FPS,dimPixel):\n",
    "    print(\"Calculando Velocidad\")\n",
    "    #Calcular la distancia recorrida en pixeles\n",
    "    dist = math.sqrt((int(coorFinal[0][0]) - int(coorInicial[3][0]))**2 + (int(coorFinal[0][1]) - int(coorInicial[3][1]))**2)  \n",
    "    \n",
    "    frames_dist = nFrameF - nFrameI\n",
    "    tiempo_trans = (1/FPS) * frames_dist\n",
    "    \n",
    "    #distancia en metros\n",
    "    dist = (dist*dimPixel)/100\n",
    "    #Velocidad en KM/H\n",
    "    velocidad = (dist / tiempo_trans) * 3.6\n",
    "    #print(\"Distancia en metros: {} recorridos\".format(dist))\n",
    "    #print(\"Velocidad: {} km/h\".format(velocidad))\n",
    "    return int(velocidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(str(PATH_VIDEO))            # Captura del video por OpenCV\n",
    "Numframe = 0                                      # Numero de frame actual\n",
    "FRAME_STOP = 1000                                 # Frame Limite a procesar\n",
    "Total_fr = cap.get(cv.CAP_PROP_FRAME_COUNT)       # Total de frames del video\n",
    "ANCHO_V  = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))  # float ~ Ancho del video\n",
    "ALTO_V = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))   # float ~ Alto del video\n",
    "FPS_V = int(cap.get(cv.CAP_PROP_FPS))             # Frame por segundos (Frame per second)\n",
    "TEXT_FONT = cv.FONT_HERSHEY_PLAIN                 # Estilo de texto de openCV\n",
    "\n",
    "# Cargar codec seleccionado (*mp4 es por defecto útil en opencv para procesar videos en formatos MP4 )\n",
    "fourcc = cv.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "# Establecer la configuracion del escritor del Video de OpenCV (VideoWriter)\n",
    "# Formato de VideoWriter(VIDEO DESTINO, CODEC, FPS, Dimensiones de los frames(Ancho,Alto))\n",
    "out = cv.VideoWriter('../Videos/Video_pa.mp4',fourcc, FPS_V, (ANCHO_V,ALTO_V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escala de centimetros cuadrados de un pixel\n",
    "DIM_PIXEL = 2\n",
    "#3.04  #3.3\n",
    "CAR_DETECTIONS = 0\n",
    "CAR_DETECTED = False\n",
    "COORD_INICO = []\n",
    "FRAME_INICIO = 0\n",
    "VELOCIDAD_CARRO = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infiriendo Frame: 499 de 681.0\n",
      "Inferencia completa ~ video Guardado!\n"
     ]
    }
   ],
   "source": [
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        Numframe += 1\n",
    "        if (Numframe > 350) & (Numframe < 500): #454: #(Numframe > 410) & (Numframe < 500): # FRAME_STOP:\n",
    "            calle = frame[140:290, 100:600]\n",
    "            clear_output(wait=True)    \n",
    "            print(\"Infiriendo Frame: {} de {}\".format(Numframe,Total_fr))\n",
    "            \n",
    "            #Inferir la imagen y obtener coordenadas de la detección\n",
    "            coordenadas_detectadas = inferir_imagen(MODEL_DETECTION,calle)\n",
    "            \n",
    "            #Dibujar las detecciones en el frame si fuerón encontrados autos\n",
    "            if (len(coordenadas_detectadas)> 0) & (Numframe < (Total_fr-3)) :              \n",
    "                nCoord = []\n",
    "                for coordenada in coordenadas_detectadas:\n",
    "                    nCoord = conversion_Coordenadas(coordenada,calle.shape[1],calle.shape[0])\n",
    "                    calle = cv.rectangle(calle, \n",
    "                                (int(nCoord[0][0]),int(nCoord[0][1])), (int(nCoord[2][0]),int(nCoord[2][1])), (0,0,255), 2) \n",
    "                \n",
    "                #print(\"Carros Detectados\")\n",
    "                if ((CAR_DETECTIONS < 3) & (CAR_DETECTED==False)):\n",
    "                    CAR_DETECTIONS += 1\n",
    "                elif ((CAR_DETECTIONS == 3) & (CAR_DETECTED == False)):\n",
    "                    CAR_DETECTED = True\n",
    "                    COORD_INICO = nCoord\n",
    "                    #print(\"Carro Detectado\")\n",
    "                    CAR_DETECTIONS += 1\n",
    "                    FRAME_INICIO = Numframe\n",
    "                    \n",
    "            elif CAR_DETECTED:\n",
    "                CAR_DETECTIONS -= 1\n",
    "                if CAR_DETECTIONS == 0:\n",
    "                    CAR_DETECTED = False\n",
    "                    VELOCIDAD_CARRO = calcVelocidad(COORD_INICO,nCoord,FRAME_INICIO,Numframe,FPS_V,DIM_PIXEL)\n",
    "            \n",
    "            #Aplicar un blur\n",
    "            frame = cv.blur(frame,(10,10))\n",
    "            frame[140:290, 100:600] = calle\n",
    "            frame = cv.putText(frame, 'Frame : {} Velocidad {} KM/H'.format(Numframe,VELOCIDAD_CARRO), (10,30), TEXT_FONT,2, (0,255,0), 2) \n",
    "            finalFrame = cv.cvtColor(np.asarray(frame), cv.COLOR_RGB2BGR)  #Converion de RGB a BGR\n",
    "             \n",
    "            #display(Image.fromarray(calle))\n",
    "            #Mostrar frame como imagen\n",
    "            #display(Image.fromarray(finalFrame))\n",
    "            #print(nCoord)\n",
    "            #Escribir el frame en el video\n",
    "            out.write(finalFrame)              \n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Liberar la memoria utilizada\n",
    "# del procesamiento del video(cap)\n",
    "# y su escritura (out)\n",
    "cap.release()\n",
    "out.release()\n",
    "print(\"Inferencia completa ~ video Guardado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversión Completa\n"
     ]
    }
   ],
   "source": [
    "# Comando para conversion de video [El proceso puede tardar unos segundos]\n",
    "!ffmpeg -i ../Videos/Video_pa.mp4 -c:v libx264 ../Videos/Video_pfb.mp4 -y 2> /dev/null\n",
    "print(\"Conversión Completa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style> video {  max-width: 100%;  height: auto; } </style>\n",
       "    <video alt=\"test\" controls autoplay>\n",
       "    <source src=\"../Videos/Video_pfb.mp4\" type=\"video/webm\"> \n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el video codificado en la Notebook\n",
    "HTML(\"\"\"\n",
    "<style> video {  max-width: 100%;  height: auto; } </style>\n",
    "    <video alt=\"test\" controls autoplay>\n",
    "    <source src=\"../Videos/Video_pfb.mp4\" type=\"video/webm\"> \n",
    "    </video>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
